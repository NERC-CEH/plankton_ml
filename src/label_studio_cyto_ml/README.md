This documentation was generated by [creating an ML backend with Label Studio](https://github.com/HumanSignal/label-studio-ml-backend?tab=readme-ov-file#2-create-empty-ml-backend) and is adapted to how we are running it here.
These docs may move elsewhere and be replaced with links.

## Running with podman (recommended)

`podman` is our preferred alternative to docker (it can be run without admin privileges).

The `Dockerfile` for Label Studio ML is in the root of this project. It's there because it needs a _build context_ that includes the `./models` directory.

`podman compose` can be used both to build the image and to run it, along with Label Studio, for testing.

`pip install podman-compose`

* [podman compose docs](https://docs.podman.io/en/latest/markdown/podman-compose.1.html)

### Build the image

```
cd src/label_studio_cyto_ml
podman compose build
```

### Run with Label Studio

The following should bring up two docker containers, one for the Label Studio frontend, one for the backend, plus a data volume that they both share (used to store a local database with annotation tasks).
```
podman compose up [-d]
```

Bring them down safely with

```
podman compose down
```

2. Validate that backend is running

```bash
$ curl http://localhost:9090/
{"status":"UP"}
```

3. Connect to the backend from Label Studio running on the same host: go to your project `Settings -> Machine Learning -> Add Model` and specify `http://ml-backend:9090` as a URL.

## Running without Docker (Advanced)

To run the ML backend without Docker, you have to clone the repository and install all dependencies using pip:

If needed, create a python environment first, then install the dependencies into it:
```bash
python -m venv ml-backend
source ml-backend/bin/activate
cd src/label_studio_cyto_ml
pip install -r requirements.txt
```

The main project's `pyproject.toml` has the same dependencies in it.

Then you can start the ML backend:

```bash
label-studio-ml start ./dir_with_your_model
```

# Configuration
Parameters can be set in `docker-compose.yml` before running the container.


The following common parameters are available:
- `BASIC_AUTH_USER` - specify the basic auth user for the model server
- `BASIC_AUTH_PASS` - specify the basic auth password for the model server
- `LOG_LEVEL` - set the log level for the model server
- `WORKERS` - specify the number of workers for the model server
- `THREADS` - specify the number of threads for the model server

# Customization

The ML backend can be customized by adding your own models inside the `./models` directory and logic into the file `model.py` 